{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56f8120-f7ac-473f-907c-84eb3bf0ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd = /root/autodl-tmp/models--lion-ai--MedImageInsights/snapshots/1\n",
      "sys.path[0] = /root/miniconda3/lib/python312.zip\n",
      "has medimageinsightmodel.py in cwd? True\n",
      "cwd files (first 50): ['.gitattributes', '.gitignore', '.idea', '.python-version', '2024.09.27', 'MedImageInsight', 'README.md', 'example.py', 'fastapi_app.py', 'flask_app.py', 'medimageinsightmodel.py', 'pyproject.toml', 'requirements.txt', 'uv.lock', '.ipynb_checkpoints', '__pycache__', 'MI_finetune.ipynb', 'best_mi2_cxr4.pt']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"cwd =\", os.getcwd())\n",
    "print(\"sys.path[0] =\", sys.path[0])\n",
    "print(\"has medimageinsightmodel.py in cwd?\", Path(\"medimageinsightmodel.py\").exists())\n",
    "print(\"cwd files (first 50):\", [p.name for p in Path(\".\").iterdir()][:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d28169e-c71d-41cc-8a95-bfcfecec26e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits = 1\n",
      "-> /root/autodl-tmp/models--lion-ai--MedImageInsights/snapshots/1/medimageinsightmodel.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "hits = list(Path(\".\").rglob(\"medimageinsightmodel.py\"))\n",
    "print(\"hits =\", len(hits))\n",
    "for p in hits[:10]:\n",
    "    print(\"->\", p.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0925d61-2c0f-459d-8a33-cf2872312920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ok ✅ <class 'medimageinsightmodel.MedImageInsight'> from /root/autodl-tmp/models--lion-ai--MedImageInsights/snapshots/1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "repo_dir = str(hits[0].parent.resolve())\n",
    "sys.path.insert(0, repo_dir)\n",
    "\n",
    "from medimageinsightmodel import MedImageInsight\n",
    "print(\"import ok ✅\", MedImageInsight, \"from\", repo_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb991e3-d078-40c7-b0be-9f2fc15f6fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1\n",
      "/root/autodl-tmp/models--lion-ai--MedImageInsights/snapshots/1/2024.09.27/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path.home() / \"autodl-tmp\" / \"models--lion-ai--MedImageInsights\"\n",
    "cfgs = list(root.rglob(\"config.yaml\"))\n",
    "print(\"found\", len(cfgs))\n",
    "for p in cfgs[:10]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c65d0c-5cfa-45dc-8599-d0499e51e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 0) 可改的配置\n",
    "# -------------------------\n",
    "TRAIN_DIR = \"/root/autodl-tmp/train\"\n",
    "VAL_DIR   = \"/root/autodl-tmp/val\"\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "IMAGE_SIZE  = 512          # 你要 >400，建议先 512；显存不够改 448\n",
    "BATCH_SIZE  = 256            # OOM 就改小\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS      = 20\n",
    "\n",
    "# 分阶段：先训 head 再训 backbone\n",
    "HEAD_ONLY_EPOCHS = 0\n",
    "\n",
    "# 学习率（常用设置：head 大，backbone 小）\n",
    "LR_HEAD     = 1e-3\n",
    "LR_BACKBONE = 2e-5\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "# 梯度累积：等效 batch = BATCH_SIZE * GRAD_ACCUM\n",
    "GRAD_ACCUM = 1             # 显存紧就设 2/4/8\n",
    "\n",
    "# label smoothing（可选）\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# AMP 混合精度\n",
    "USE_AMP = True\n",
    "\n",
    "# 是否开启水平翻转（胸片一般默认关）\n",
    "USE_HFLIP = False\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 1) 轻量胸片增强（不会乱裁）\n",
    "# -------------------------\n",
    "def build_transforms_for_mi2(preprocess):\n",
    "    # preprocess 是 MI2 自带的 build_transforms(...) 产物（PIL->Tensor->Normalize） :contentReference[oaicite:3]{index=3}\n",
    "    # 我们在它前面加“安全增强”，尽量不裁掉病灶\n",
    "    aug = [\n",
    "        transforms.Lambda(lambda im: im.convert(\"RGB\") if getattr(im, \"mode\", None) != \"RGB\" else im),\n",
    "        transforms.Resize(int(IMAGE_SIZE * 1.10)),\n",
    "    ]\n",
    "    if USE_HFLIP:\n",
    "        aug.append(transforms.RandomHorizontalFlip(p=0.5))\n",
    "    aug += [\n",
    "        transforms.RandomAffine(\n",
    "            degrees=5,\n",
    "            translate=(0.03, 0.03),\n",
    "            scale=(0.95, 1.05),\n",
    "            interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "            fill=0\n",
    "        ),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.10, contrast=0.10)], p=0.8),\n",
    "        transforms.RandomAutocontrast(p=0.2),\n",
    "    ]\n",
    "    train_tfm = transforms.Compose(aug + [preprocess])\n",
    "\n",
    "    val_tfm = transforms.Compose([\n",
    "        transforms.Lambda(lambda im: im.convert(\"RGB\") if getattr(im, \"mode\", None) != \"RGB\" else im),\n",
    "        transforms.Resize(int(IMAGE_SIZE * 1.10)),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        preprocess,\n",
    "    ])\n",
    "    return train_tfm, val_tfm\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 2) 组装可训练的 MI2 分类模型\n",
    "# -------------------------\n",
    "class MI2Classifier(nn.Module):\n",
    "    def __init__(self, mi2_backbone: nn.Module, embed_dim: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.backbone = mi2_backbone\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        # 定位 blocks（只做一次）\n",
    "        self._blocks_name, self._blocks = _find_best_blocklist(self.backbone)\n",
    "        print(f\"[MI2Classifier] using blocks: {self._blocks_name} (len={len(self._blocks)})\")\n",
    "\n",
    "    def set_trainable(self, last_k: int):\n",
    "        \"\"\"\n",
    "        last_k=0: 冻结整个 backbone（只训 head）\n",
    "        last_k>0: 冻结 backbone，只解冻最后 last_k 个 block（再加 head）\n",
    "        \"\"\"\n",
    "        freeze_all_params(self.backbone)\n",
    "\n",
    "        if last_k > 0:\n",
    "            last_k = min(last_k, len(self._blocks))\n",
    "            for blk in self._blocks[-last_k:]:\n",
    "                unfreeze_params(blk)\n",
    "\n",
    "        # head 永远可训练\n",
    "        unfreeze_params(self.head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 不能用 no_grad 包住 encode_image（因为你可能只解冻了部分层）\n",
    "        feats = self.backbone.encode_image(x)\n",
    "        logits = self.head(feats)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "def infer_embed_dim(mi2_model, sample_tensor: torch.Tensor) -> int:\n",
    "    mi2_model.eval()\n",
    "    with torch.no_grad():\n",
    "        feat = mi2_model.encode_image(sample_tensor)\n",
    "    return int(feat.shape[-1])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3) 训练 / 验证\n",
    "# -------------------------\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    for step, (xb, yb) in enumerate(loader):\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss = loss / GRAD_ACCUM\n",
    "\n",
    "        if USE_AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if (step + 1) % GRAD_ACCUM == 0:\n",
    "            if USE_AMP:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        total_loss += loss.item() * GRAD_ACCUM\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        y_true.append(yb.detach().cpu().numpy())\n",
    "        y_pred.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return total_loss / max(1, len(loader)), acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        total_loss += loss.item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        y_true.append(yb.cpu().numpy())\n",
    "        y_pred.append(pred.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return total_loss / max(1, len(loader)), acc, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96b688f-94a3-45b2-96b0-d990c3b3a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe2effe-11a6-4c0f-9d3f-f083c64dcb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def _find_best_blocklist(backbone: nn.Module):\n",
    "    \"\"\"\n",
    "    尝试在各种常见结构里找到 transformer blocks / layers (ModuleList)。\n",
    "    找不到就退化：挑一个“最长的 ModuleList”当 blocks。\n",
    "    \"\"\"\n",
    "    # 1) 常见显式路径（按经验覆盖 CLIP/ViT/Transformer encoder）\n",
    "    candidates = [\n",
    "        (\"visual.transformer.resblocks\", lambda m: m.visual.transformer.resblocks),\n",
    "        (\"transformer.resblocks\",        lambda m: m.transformer.resblocks),\n",
    "        (\"vision_model.encoder.layers\",  lambda m: m.vision_model.encoder.layers),\n",
    "        (\"vision_model.blocks\",          lambda m: m.vision_model.blocks),\n",
    "        (\"encoder.layers\",               lambda m: m.encoder.layers),\n",
    "        (\"blocks\",                       lambda m: m.blocks),\n",
    "        (\"layers\",                       lambda m: m.layers),\n",
    "    ]\n",
    "    for name, getter in candidates:\n",
    "        try:\n",
    "            blocks = getter(backbone)\n",
    "            if isinstance(blocks, (nn.ModuleList, list, tuple)) and len(blocks) > 0:\n",
    "                return name, blocks\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) 兜底：遍历所有 ModuleList，选最长的那个\n",
    "    best = None\n",
    "    best_name = None\n",
    "    for n, mod in backbone.named_modules():\n",
    "        if isinstance(mod, nn.ModuleList) and len(mod) > 0:\n",
    "            # 粗略判断：里面大部分是 nn.Module\n",
    "            if all(isinstance(x, nn.Module) for x in mod):\n",
    "                if best is None or len(mod) > len(best):\n",
    "                    best = mod\n",
    "                    best_name = n\n",
    "    if best is None:\n",
    "        raise RuntimeError(\"找不到 backbone 的 blocks/layers(ModuleList)。请把 mi.model 的结构打印出来我来定点改。\")\n",
    "    return best_name, best\n",
    "\n",
    "def freeze_all_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "def unfreeze_params(module: nn.Module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "def count_trainable_params(module: nn.Module):\n",
    "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c42db5-1bce-4a55-a02e-82ff6c39a070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: cuda\n",
      "MI2 device: cuda\n"
     ]
    }
   ],
   "source": [
    "from medimageinsightmodel import MedImageInsight\n",
    "\n",
    "mi = MedImageInsight(\n",
    "    model_dir=\"/root/autodl-tmp/models--lion-ai--MedImageInsights/snapshots/1/2024.09.27\",\n",
    "    vision_model_name=\"medimageinsigt-v1.0.0.pt\",\n",
    "    language_model_name=\"language_model.pth\",\n",
    ")\n",
    "mi.load_model()\n",
    "device = mi.device\n",
    "print(\"MI2 device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a57966-6312-481a-9414-8e54773c3298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['class 0', 'class 1', 'class 2', 'class 3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_dim = 1024\n",
      "[MI2Classifier] using blocks: lang_encoder.resblocks (len=16)\n",
      "Using DataParallel on 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10740/3783164865.py:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
     ]
    }
   ],
   "source": [
    "train_tfm, val_tfm = build_transforms_for_mi2(mi.preprocess)\n",
    "\n",
    "train_ds = ImageFolder(TRAIN_DIR, transform=train_tfm)\n",
    "val_ds   = ImageFolder(VAL_DIR,   transform=val_tfm)\n",
    "\n",
    "print(\"classes:\", train_ds.classes)\n",
    "assert len(train_ds.classes) == NUM_CLASSES, \"NUM_CLASSES 与文件夹类别数不一致\"\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# 推断 embed dim\n",
    "x0, _ = train_ds[0]\n",
    "x0 = x0.unsqueeze(0).to(device)\n",
    "embed_dim = infer_embed_dim(mi.model, x0)\n",
    "print(\"embed_dim =\", embed_dim)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:0\")  # 主卡\n",
    "model = MI2Classifier(mi.model, embed_dim=embed_dim, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "if torch.cuda.device_count() >= 2:\n",
    "    print(\"Using DataParallel on\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1])  # 双卡 0,1\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "best_acc = -1.0\n",
    "best_path = \"best_mi2_cxr4.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c729e0-c06e-4f46-a0ff-c6d05811c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_tqdm(model, loader, optimizer, criterion, device, scaler=None, epoch=0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Train e{epoch:02d}\", leave=False)\n",
    "    for step, (xb, yb) in enumerate(pbar, start=1):\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb) / GRAD_ACCUM\n",
    "\n",
    "        if USE_AMP:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if step % GRAD_ACCUM == 0:\n",
    "            if USE_AMP:\n",
    "                scaler.step(optimizer); scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # 统计（用未除以 accum 的真实 loss）\n",
    "        loss_item = float(loss.detach()) * GRAD_ACCUM\n",
    "        total_loss += loss_item\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == yb).sum().item())\n",
    "        total += int(yb.size(0))\n",
    "\n",
    "        avg_loss = total_loss / step\n",
    "        avg_acc = correct / max(1, total)\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{avg_acc:.4f}\")\n",
    "\n",
    "    return total_loss / max(1, len(loader)), correct / max(1, total)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch_tqdm(model, loader, criterion, device, epoch=0):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Val   e{epoch:02d}\", leave=False)\n",
    "    for step, (xb, yb) in enumerate(pbar, start=1):\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "        loss_item = float(loss.detach())\n",
    "        total_loss += loss_item\n",
    "\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == yb).sum().item())\n",
    "        total += int(yb.size(0))\n",
    "\n",
    "        y_true.append(yb.cpu().numpy())\n",
    "        y_pred.append(pred.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / step\n",
    "        avg_acc = correct / max(1, total)\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{avg_acc:.4f}\")\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "\n",
    "    return total_loss / max(1, len(loader)), correct / max(1, total), y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b6e6bf-f7d2-4060-992e-d9f1ddf7326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_bar = tqdm(range(1, EPOCHS + 1), desc=\"Epochs\")\n",
    "# torch.cuda.empty_cache()\n",
    "# for epoch in epochs_bar:\n",
    "#     m = model.module if isinstance(model, nn.DataParallel) else model\n",
    "#     if epoch <= HEAD_ONLY_EPOCHS:\n",
    "#         m.freeze_backbone(True)\n",
    "#         params = [\n",
    "#             {\"params\": m.head.parameters(), \"lr\": LR_HEAD, \"weight_decay\": WEIGHT_DECAY},\n",
    "#         ]\n",
    "#         stage = \"head\"\n",
    "#     else:\n",
    "#         m.freeze_backbone(False)\n",
    "#         params = [\n",
    "#             {\"params\": m.head.parameters(), \"lr\": LR_HEAD, \"weight_decay\": WEIGHT_DECAY},\n",
    "#             {\"params\": m.backbone.parameters(), \"lr\": LR_BACKBONE, \"weight_decay\": WEIGHT_DECAY},\n",
    "#         ]\n",
    "#         stage = \"finetune\"\n",
    "#     optimizer = optim.AdamW(params)\n",
    "\n",
    "#     tr_loss, tr_acc = train_one_epoch_tqdm(model, train_loader, optimizer, criterion, device, scaler=scaler, epoch=epoch)\n",
    "#     va_loss, va_acc, y_true, y_pred = eval_one_epoch_tqdm(model, val_loader, criterion, device, epoch=epoch)\n",
    "\n",
    "#     msg = f\"e{epoch:02d} [{stage}] tr_loss={tr_loss:.4f} tr_acc={tr_acc:.4f} | va_loss={va_loss:.4f} va_acc={va_acc:.4f}\"\n",
    "#     epochs_bar.set_postfix_str(msg)\n",
    "#     print(msg)\n",
    "\n",
    "#     if va_acc > best_acc:\n",
    "#         best_acc = va_acc\n",
    "#         state_dict = (model.module.state_dict()\n",
    "#               if isinstance(model, nn.DataParallel)\n",
    "#               else model.state_dict())\n",
    "#         torch.save({\n",
    "#             \"epoch\": epoch,\n",
    "#             \"best_acc\": best_acc,\n",
    "#             \"state_dict\": state_dict,\n",
    "#             \"classes\": train_ds.classes,\n",
    "#             \"embed_dim\": embed_dim,\n",
    "#         }, best_path)\n",
    "#         print(\"  ✅ saved:\", best_path, \"best_acc=\", best_acc)\n",
    "\n",
    "# print(\"\\nBest val acc:\", best_acc)\n",
    "# print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "# print(classification_report(y_true, y_pred, target_names=train_ds.classes, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb235504-93f4-46e9-9da2-42360bf4fffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f14f1690164a7cac70e7cffb2ada78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] stage=last2+head  trainable(backbone)=25.19M  trainable(total)=25.20M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d47e0fe7984f2d8a1ff1d93e5f2781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e01:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10740/1820075033.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb7b6044fe640a597a6741da8594ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e01:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10740/1820075033.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01/20] last2+head | train loss=1.3090 acc=0.6718 | val loss=1.2251 acc=0.7141\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.7140902872777017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e0e1cff69847b8add603c594976143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e02:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95936456c99749ddb37b6af204ee7d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e02:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 02/20] last2+head | train loss=1.1711 acc=0.7444 | val loss=1.0969 acc=0.7620\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.761969904240766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e498a54692b4ee78529f741b4c1ae2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e03:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32f6a147936495b929898c82b3c8c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e03:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 03/20] last2+head | train loss=1.0585 acc=0.7735 | val loss=0.9902 acc=0.7818\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.7818057455540356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a29ded0d7b473e8bcff2880c829dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e04:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e52c523c54e3bbbbb5cc6abbc0d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e04:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 04/20] last2+head | train loss=0.9631 acc=0.7879 | val loss=0.9002 acc=0.7934\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.7934336525307798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d1b0e63fb4c61818a149fc1f7d149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e05:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56073aef7a64df9acb5d2a55762e24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e05:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 05/20] last2+head | train loss=0.8825 acc=0.8045 | val loss=0.8258 acc=0.8064\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8064295485636115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4a5071872745058ebf438a9840447a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e06:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8321eae55094a598bc9f9e4cf61ade6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e06:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 06/20] last2+head | train loss=0.8149 acc=0.8216 | val loss=0.7668 acc=0.8290\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8290013679890561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebcd86d84724b749fbff343aff61440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e07:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d5a70c7b694b3284860869400045b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e07:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 07/20] last2+head | train loss=0.7634 acc=0.8430 | val loss=0.7195 acc=0.8570\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8570451436388509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc04d5ee0794f06b7bb026aecef28e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e08:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50203354fc614094a9c0595d47a86479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e08:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 08/20] last2+head | train loss=0.7218 acc=0.8569 | val loss=0.6821 acc=0.8694\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8693570451436389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d941ae93087b4dd8ad889c3fb52fc50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e09:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abab063220449c9a29f2d27cbe90ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e09:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 09/20] last2+head | train loss=0.6873 acc=0.8615 | val loss=0.6539 acc=0.8762\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8761969904240766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f13b1b4424458cbea9baf089097022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e10:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a8822878b74a1982865048b02ac04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e10:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/20] last2+head | train loss=0.6624 acc=0.8651 | val loss=0.6320 acc=0.8796\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8796169630642955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3d7993577c445dbaa99d2199eba83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e11:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404d8b6da0c84ea3a91e2c9225f9c5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e11:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/20] last2+head | train loss=0.6422 acc=0.8718 | val loss=0.6163 acc=0.8817\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8816689466484268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9092d3cd3349f79d1611fece762460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e12:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6a4f48b6c844d49dbbfc6934c24750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e12:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/20] last2+head | train loss=0.6276 acc=0.8742 | val loss=0.6038 acc=0.8789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf43b07e4cb48b2b93e01847cb75db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e13:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67adc5b223ca47bfa301ee5e4a34e9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e13:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/20] last2+head | train loss=0.6164 acc=0.8757 | val loss=0.5946 acc=0.8837\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8837209302325582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0313582ca942495fbcea59c65d61bfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e14:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b6ff86c0cb43f5b914f2ead8ca50f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e14:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/20] last2+head | train loss=0.6074 acc=0.8757 | val loss=0.5878 acc=0.8796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f888ad206d49179283702f33833cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e15:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe1f28434c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad2f2ff7a7744038a65f1f7e998d10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e15:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/20] last2+head | train loss=0.6010 acc=0.8783 | val loss=0.5829 acc=0.8824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5190f17526ab448abf7bead0b0fb1aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e16:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35d0d2bee2d4d5fb0ff013cbddc8f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e16:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/20] last2+head | train loss=0.5961 acc=0.8783 | val loss=0.5791 acc=0.8830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de685360d9334d298a0df0f253d8fc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e17:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70a01959c2d4b57b9b526acf0562894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e17:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/20] last2+head | train loss=0.5925 acc=0.8767 | val loss=0.5760 acc=0.8830\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d31bb10a094e7f94537d52db3bab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e18:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4639410117a44ab85e7d329f37c46cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e18:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/20] last2+head | train loss=0.5893 acc=0.8815 | val loss=0.5742 acc=0.8810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57dd19a3d2b4ec1b4af682e413ac911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e19:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82680562da944c3285580d67f4c59be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e19:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/20] last2+head | train loss=0.5872 acc=0.8808 | val loss=0.5722 acc=0.8851\n",
      "  ✅ saved: best_mi2_cxr4.pt best_acc= 0.8850889192886456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4e8cf9e6814d92a3f3fd746c3105fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train e20:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0831fe2acd349f388e55ffac8d98290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val   e20:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/20] last2+head | train loss=0.5841 acc=0.8793 | val loss=0.5706 acc=0.8844\n"
     ]
    }
   ],
   "source": [
    "LAST_K_BLOCKS = 2  # ✅ 你想训练的“最后几层”，建议先 1~3 试\n",
    "epochs_bar = tqdm(range(1, EPOCHS + 1), desc=\"Epochs\")\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in epochs_bar:\n",
    "    m = model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "    if epoch <= HEAD_ONLY_EPOCHS:\n",
    "        m.set_trainable(last_k=0)        # 只训 head\n",
    "        stage = \"head\"\n",
    "        params = [{\"params\": m.head.parameters(), \"lr\": LR_HEAD, \"weight_decay\": WEIGHT_DECAY}]\n",
    "    else:\n",
    "        m.set_trainable(last_k=LAST_K_BLOCKS)  # ✅ 只训最后K层 + head\n",
    "        stage = f\"last{LAST_K_BLOCKS}+head\"\n",
    "        # 只把 requires_grad=True 的 backbone 参数交给 optimizer（避免误加冻结层）\n",
    "        backbone_trainable = [p for p in m.backbone.parameters() if p.requires_grad]\n",
    "        params = [\n",
    "            {\"params\": m.head.parameters(), \"lr\": LR_HEAD, \"weight_decay\": WEIGHT_DECAY},\n",
    "            {\"params\": backbone_trainable, \"lr\": LR_BACKBONE, \"weight_decay\": WEIGHT_DECAY},\n",
    "        ]\n",
    "\n",
    "    optimizer = optim.AdamW(params)\n",
    "\n",
    "    # 可选：打印一下确认只训了哪些参数\n",
    "    if epoch in [1, HEAD_ONLY_EPOCHS, HEAD_ONLY_EPOCHS + 1]:\n",
    "        print(f\"[epoch {epoch}] stage={stage}  trainable(backbone)={count_trainable_params(m.backbone)/1e6:.2f}M  trainable(total)={count_trainable_params(m)/1e6:.2f}M\")\n",
    "\n",
    "    tr_loss, tr_acc = train_one_epoch_tqdm(model, train_loader, optimizer, criterion, device, scaler=scaler, epoch=epoch)\n",
    "    va_loss, va_acc, y_true, y_pred = eval_one_epoch_tqdm(model, val_loader, criterion, device, epoch=epoch)\n",
    "\n",
    "    print(f\"[Epoch {epoch:02d}/{EPOCHS}] {stage} | train loss={tr_loss:.4f} acc={tr_acc:.4f} | val loss={va_loss:.4f} acc={va_acc:.4f}\")\n",
    "\n",
    "    # 保存 best（DP 情况保存 module）\n",
    "    state_dict = (model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict())\n",
    "    if va_acc > best_acc:\n",
    "        best_acc = va_acc\n",
    "        torch.save({\"epoch\": epoch, \"best_acc\": best_acc, \"state_dict\": state_dict,\n",
    "                    \"classes\": train_ds.classes, \"embed_dim\": embed_dim}, best_path)\n",
    "        print(\"  ✅ saved:\", best_path, \"best_acc=\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049274e8-000e-42d6-8e69-498043a87c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b2a343-7421-4ab7-98b2-e11f38e01f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d45a6-a17d-4283-8318-c9f3d81d34ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
