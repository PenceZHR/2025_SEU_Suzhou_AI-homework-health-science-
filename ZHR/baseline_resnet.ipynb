{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd372841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights, resnet34, ResNet34_Weights, resnet50, ResNet50_Weights\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0dec38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'baseline_Conv_transformer.ipynb',\n",
       " 'baseline_resnet.ipynb',\n",
       " 'BiomedCLIP_baseline.ipynb',\n",
       " 'class 0',\n",
       " 'class 1',\n",
       " 'class 2',\n",
       " 'class 3',\n",
       " 'CLIP ViT-L14.ipynb',\n",
       " 'medsig.ipynb',\n",
       " 'MedSigLIP.ipynb',\n",
       " 'medsiglip448_cls_best_acc0.8762.pth',\n",
       " 'medsig_lora.ipynb',\n",
       " 'trainlog_19.log',\n",
       " 'trainlog_24.log',\n",
       " 'trainlog_linear.log',\n",
       " 'trainlog_resnet.log']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_DIR = Path(\"D:/OneDriveFiles/OneDrive/人工智能基础期末/dataset2\")\n",
    "OUT_DIR = Path(\"D:/OneDriveFiles/OneDrive/人工智能基础期末/data_split\")    # 拆分后的 train/val 会放在这里\n",
    "\n",
    "classes = os.listdir(RAW_DIR)\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f02a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "train_ratio = 0.8   # 训练集占 80%\n",
    "val_ratio   = 0.2   # 验证集占 20%，train_ratio + val_ratio 应该 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c241e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE   = 256\n",
    "EPOCHS       = 10\n",
    "LR           = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "TRAIN_RATIO  = 0.7\n",
    "VAL_RATIO    = 0.15     # TEST 就是剩下 0.15\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"使用设备:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec36384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现的类别： ['class 0', 'class 1', 'class 2', 'class 3']\n"
     ]
    }
   ],
   "source": [
    "classes = [d for d in os.listdir(RAW_DIR) if (RAW_DIR / d).is_dir()]\n",
    "print(\"发现的类别：\", classes)\n",
    "\n",
    "for phase in [\"train\", \"val\"]:\n",
    "    for cls in classes:\n",
    "        (OUT_DIR / phase / cls).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d807b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: 总数 2530, 训练 2024, 验证 506\n",
      "class 1: 总数 1345, 训练 1076, 验证 269\n",
      "class 2: 总数 1626, 训练 1300, 验证 326\n",
      "class 3: 总数 1802, 训练 1441, 验证 361\n",
      "划分完成，已保存到 D:\\OneDriveFiles\\OneDrive\\人工智能基础期末\\data_split\n"
     ]
    }
   ],
   "source": [
    "for cls in classes:\n",
    "    src_dir = RAW_DIR / cls\n",
    "    files = [f for f in os.listdir(src_dir)\n",
    "             if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    random.shuffle(files)\n",
    "    n = len(files)\n",
    "    n_train = int(n * train_ratio)\n",
    "    # val 集就是剩下的\n",
    "    train_files = files[:n_train]\n",
    "    val_files   = files[n_train:]\n",
    "\n",
    "    print(f\"{cls}: 总数 {n}, 训练 {len(train_files)}, 验证 {len(val_files)}\")\n",
    "\n",
    "    # 复制到目标文件夹（想省空间可以用 shutil.move）\n",
    "    for fname in train_files:\n",
    "        shutil.copy(src_dir / fname, OUT_DIR / \"train\" / cls / fname)\n",
    "    for fname in val_files:\n",
    "        shutil.copy(src_dir / fname, OUT_DIR / \"val\" / cls / fname)\n",
    "\n",
    "print(\"划分完成，已保存到\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf1a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别映射： {'class 0': 0, 'class 1': 1, 'class 2': 2, 'class 3': 3}\n",
      "训练集大小： 5841\n",
      "验证集大小： 1462\n"
     ]
    }
   ],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # 灰度 → 1 通道\n",
    "    transforms.Resize((224, 224)),               # 统一到 224×224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "val_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "train_set = ImageFolder(str(OUT_DIR / \"train\"), transform=train_tfm)\n",
    "val_set   = ImageFolder(str(OUT_DIR / \"val\"),   transform=val_tfm)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_set,   batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"类别映射：\", train_set.class_to_idx)\n",
    "print(\"训练集大小：\", len(train_set))\n",
    "print(\"验证集大小：\", len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c9299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别： ['class 0', 'class 1', 'class 2', 'class 3'] ，数量： 4\n"
     ]
    }
   ],
   "source": [
    "resnet_train_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),   # 灰度转 3 通道\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   # ImageNet 均值\n",
    "        std=[0.229, 0.224, 0.225],    # ImageNet 方差\n",
    "    ),\n",
    "])\n",
    "\n",
    "resnet_eval_tfm = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dir = \"D:/OneDriveFiles/OneDrive/人工智能基础期末/data_split/train\"   # 改成你自己的路径\n",
    "val_dir   = \"D:/OneDriveFiles/OneDrive/人工智能基础期末/data_split/val\"     # 改成你自己的路径\n",
    "\n",
    "resnet_train_set = ImageFolder(train_dir, transform=resnet_train_tfm)\n",
    "resnet_val_set   = ImageFolder(val_dir,   transform=resnet_eval_tfm)\n",
    "\n",
    "resnet_train_loader = DataLoader(resnet_train_set, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "resnet_val_loader   = DataLoader(resnet_val_set,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = resnet_train_set.classes\n",
    "num_classes = len(classes)\n",
    "print(\"类别：\", classes, \"，数量：\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc38b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # 加载预训练 ResNet18\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        self.backbone = resnet18(weights=weights)\n",
    "\n",
    "        # 不用改第一层，因为我们已经在 transform 里把图像转成 RGB 3 通道了\n",
    "\n",
    "        # 替换最后一层全连接为 num_classes\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c13df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # 加载预训练 ResNet18\n",
    "        weights = ResNet34_Weights.IMAGENET1K_V1\n",
    "        self.backbone = resnet34(weights=weights)\n",
    "\n",
    "        # 不用改第一层，因为我们已经在 transform 里把图像转成 RGB 3 通道了\n",
    "\n",
    "        # 替换最后一层全连接为 num_classes\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35df39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    progress = tqdm(loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for x, y in progress:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "        all_labels.extend(y.detach().cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1  = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    progress = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "    for x, y in progress:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "        all_labels.extend(y.detach().cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1  = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "    return avg_loss, acc, f1, all_labels, all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d0bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.conv1.weight True\n",
      "backbone.bn1.weight True\n",
      "backbone.bn1.bias True\n",
      "backbone.layer1.0.conv1.weight True\n",
      "backbone.layer1.0.bn1.weight True\n",
      "backbone.layer1.0.bn1.bias True\n",
      "backbone.layer1.0.conv2.weight True\n",
      "backbone.layer1.0.bn2.weight True\n",
      "backbone.layer1.0.bn2.bias True\n",
      "backbone.layer1.1.conv1.weight True\n",
      "backbone.layer1.1.bn1.weight True\n",
      "backbone.layer1.1.bn1.bias True\n",
      "backbone.layer1.1.conv2.weight True\n",
      "backbone.layer1.1.bn2.weight True\n",
      "backbone.layer1.1.bn2.bias True\n",
      "backbone.layer2.0.conv1.weight True\n",
      "backbone.layer2.0.bn1.weight True\n",
      "backbone.layer2.0.bn1.bias True\n",
      "backbone.layer2.0.conv2.weight True\n",
      "backbone.layer2.0.bn2.weight True\n",
      "backbone.layer2.0.bn2.bias True\n",
      "backbone.layer2.0.downsample.0.weight True\n",
      "backbone.layer2.0.downsample.1.weight True\n",
      "backbone.layer2.0.downsample.1.bias True\n",
      "backbone.layer2.1.conv1.weight True\n",
      "backbone.layer2.1.bn1.weight True\n",
      "backbone.layer2.1.bn1.bias True\n",
      "backbone.layer2.1.conv2.weight True\n",
      "backbone.layer2.1.bn2.weight True\n",
      "backbone.layer2.1.bn2.bias True\n",
      "backbone.layer3.0.conv1.weight True\n",
      "backbone.layer3.0.bn1.weight True\n",
      "backbone.layer3.0.bn1.bias True\n",
      "backbone.layer3.0.conv2.weight True\n",
      "backbone.layer3.0.bn2.weight True\n",
      "backbone.layer3.0.bn2.bias True\n",
      "backbone.layer3.0.downsample.0.weight True\n",
      "backbone.layer3.0.downsample.1.weight True\n",
      "backbone.layer3.0.downsample.1.bias True\n",
      "backbone.layer3.1.conv1.weight True\n",
      "backbone.layer3.1.bn1.weight True\n",
      "backbone.layer3.1.bn1.bias True\n",
      "backbone.layer3.1.conv2.weight True\n",
      "backbone.layer3.1.bn2.weight True\n",
      "backbone.layer3.1.bn2.bias True\n",
      "backbone.layer4.0.conv1.weight True\n",
      "backbone.layer4.0.bn1.weight True\n",
      "backbone.layer4.0.bn1.bias True\n",
      "backbone.layer4.0.conv2.weight True\n",
      "backbone.layer4.0.bn2.weight True\n",
      "backbone.layer4.0.bn2.bias True\n",
      "backbone.layer4.0.downsample.0.weight True\n",
      "backbone.layer4.0.downsample.1.weight True\n",
      "backbone.layer4.0.downsample.1.bias True\n",
      "backbone.layer4.1.conv1.weight True\n",
      "backbone.layer4.1.bn1.weight True\n",
      "backbone.layer4.1.bn1.bias True\n",
      "backbone.layer4.1.conv2.weight True\n",
      "backbone.layer4.1.bn2.weight True\n",
      "backbone.layer4.1.bn2.bias True\n",
      "backbone.fc.weight True\n",
      "backbone.fc.bias True\n"
     ]
    }
   ],
   "source": [
    "# 训练Resnet18+DropMLP\n",
    "resnet_model = ResNetClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 15\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "history_resnet = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for name, param in resnet_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68500e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\pc/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83.3M/83.3M [00:30<00:00, 2.89MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758a968c2e9a4c9787fa34f719690431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd34ff1a94642a8b33b158468ff4ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01] Train loss=1.5741 acc=0.2472 f1=0.1809 | Val loss=1.6622 acc=0.2264 f1=0.1309\n",
      "  -> 保存当前最好模型\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeff645e1585447f955b6758bdf6498d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 全量训练 ResNet18\n",
    "num_classes = 4\n",
    "resnet_model = ResNetClassifier(num_classes=num_classes).to(device)\n",
    "resnet34_model = ResNet34Classifier(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 15\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "history_resnet = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    tr_loss, tr_acc, tr_f1 = train_one_epoch(\n",
    "        resnet34_model, resnet_train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc, val_f1, _, _ = eval_one_epoch(\n",
    "        resnet34_model, resnet_val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    history_resnet[\"train_loss\"].append(tr_loss)\n",
    "    history_resnet[\"val_loss\"].append(val_loss)\n",
    "    history_resnet[\"train_acc\"].append(tr_acc)\n",
    "    history_resnet[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:02d}] \"\n",
    "        f\"Train loss={tr_loss:.4f} acc={tr_acc:.4f} f1={tr_f1:.4f} | \"\n",
    "        f\"Val loss={val_loss:.4f} acc={val_acc:.4f} f1={val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = resnet34_model.state_dict()\n",
    "        print(\"  -> 保存当前最好模型\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f902921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将最后的fc层换成MLP + Dropout\n",
    "class ResNetClassifier_DropMLP(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_p=0.5, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        self.backbone = resnet18(weights=weights)\n",
    "        \n",
    "        in_features = self.backbone.fc.in_features\n",
    "\n",
    "        # 替换 fc 头为 MLP + Dropout\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e924d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练Resnet18+DropMLP\n",
    "resnet_model = ResNetClassifier_DropMLP(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 15\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "history_resnet = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for name, param in resnet_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    tr_loss, tr_acc, tr_f1 = train_one_epoch(\n",
    "        resnet_model, resnet_train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc, val_f1, _, _ = eval_one_epoch(\n",
    "        resnet_model, resnet_val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    history_resnet[\"train_loss\"].append(tr_loss)\n",
    "    history_resnet[\"val_loss\"].append(val_loss)\n",
    "    history_resnet[\"train_acc\"].append(tr_acc)\n",
    "    history_resnet[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:02d}] \"\n",
    "        f\"Train loss={tr_loss:.4f} acc={tr_acc:.4f} f1={tr_f1:.4f} | \"\n",
    "        f\"Val loss={val_loss:.4f} acc={val_acc:.4f} f1={val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = resnet_model.state_dict()\n",
    "        print(\"  -> 保存当前最好模型\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedResNet18Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    用 ResNet18 的 conv1 ~ layer3 作为 backbone（删掉 layer4），\n",
    "    再接一个自己的分类头。\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, pretrained=True, dropout_p=0.5, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        base = resnet18(weights=weights)\n",
    "\n",
    "        # stem + layer1~3 作为 backbone\n",
    "        self.stem = nn.Sequential(\n",
    "            base.conv1,\n",
    "            base.bn1,\n",
    "            base.relu,\n",
    "            base.maxpool,\n",
    "        )\n",
    "        self.layer1 = base.layer1\n",
    "        self.layer2 = base.layer2\n",
    "        self.layer3 = base.layer3   # 不再用 layer4\n",
    "\n",
    "        # 全局池化\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)  # -> [B, 256, 1, 1]\n",
    "\n",
    "        # 256 是 layer3 输出通道数\n",
    "        in_features = 256\n",
    "\n",
    "        # 自定义 head：一个小 MLP + Dropout\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)      # 现在的特征图更大、层数更浅\n",
    "        x = self.gap(x).view(x.size(0), -1)  # [B, 256]\n",
    "        logits = self.classifier(x)          # [B, num_classes]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练Resnet18+DropMLP\n",
    "resnet_model = TruncatedResNet18Classifier(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "history_resnet = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "for name, param in resnet_model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"trainlog_resnet.log\"\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    tr_loss, tr_acc, tr_f1 = train_one_epoch(\n",
    "        resnet_model, resnet_train_loader, optimizer, criterion, device\n",
    "    )\n",
    "    val_loss, val_acc, val_f1, _, _ = eval_one_epoch(\n",
    "        resnet_model, resnet_val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    line = (\n",
    "        f\"[Epoch {epoch}] \"\n",
    "        f\"train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} | \"\n",
    "        f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    print(line)\n",
    "\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "    history_resnet[\"train_loss\"].append(tr_loss)\n",
    "    history_resnet[\"val_loss\"].append(val_loss)\n",
    "    history_resnet[\"train_acc\"].append(tr_acc)\n",
    "    history_resnet[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:02d}] \"\n",
    "        f\"Train loss={tr_loss:.4f} acc={tr_acc:.4f} f1={tr_f1:.4f} | \"\n",
    "        f\"Val loss={val_loss:.4f} acc={val_acc:.4f} f1={val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = resnet_model.state_dict()\n",
    "        print(\"  -> 保存当前最好模型\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
